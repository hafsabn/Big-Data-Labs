#  Big Data Labs

Here are my solutions to lab assignments from the **Big Data** module during my university journey. These labs cover a wide range of big data technologies, from distributed computing with Hadoop and Spark to machine learning, graph processing..etc

## Lab Overview

###  Lab 1: Hadoop
- Introduction to the Hadoop ecosystem.
- Hands-on with HDFS and basic MapReduce concepts.

###  Lab 2: Spark RDD
- Worked with **Resilient Distributed Datasets (RDDs)** in Apache Spark.
- Explored transformations and actions for distributed data processing.

###  Lab 3: Spark SQL
- Used **Spark SQL** for querying structured data.
- Integrated DataFrames with SQL queries.

###  Lab 4: Spark MLlib
- Applied machine learning algorithms using **Spark MLlib**.
- Built and evaluated models with pipelines.

###  Lab 5: Deep Learning with Spark
- Integrated deep learning techniques into Spark workflows.
- Trained basic neural networks using Spark-compatible tools.

###  Lab 6: Spark GraphFrames
- Used **GraphFrames** for graph processing on big data.

###  Lab 7: Stream Processing
- Implemented real-time processing with **Spark Streaming**.
- Handled continuous data from sources like Kafka or sockets.

###  Lab 8: Apache Airflow
- Built and scheduled data pipelines using **Apache Airflow**.
- Created DAGs for automated workflow management.



**Note**: Each lab folder includes a `PDF` file containing the original lab statement.
