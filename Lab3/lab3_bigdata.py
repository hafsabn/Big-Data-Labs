# -*- coding: utf-8 -*-
"""Lab3_bigData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BYhuc0yxBM10DtptKfGm1Q3AQtfhG63I

# Lab3
"""

#! pip install pyspark

# import pandas as pd
# from google.colab import files
# uploaded = files.upload()

from pyspark.sql import SparkSession
from pyspark import SparkConf
from pyspark.sql.functions import *

nomappli = "lab3"
spark = SparkSession.builder.appName(nomappli).getOrCreate()

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.window import Window
from pyspark.sql.types import StructType, StructField, StringType, IntegerType
# Define schema
schema = StructType([
    StructField("ngram", StringType(), True),
    StructField("Year", IntegerType(), True),
    StructField("Count", IntegerType(), True),
    StructField("Pages", IntegerType(), True),
    StructField("Books", IntegerType(), True)
])

df = spark.read.csv("hdfs://hadoop-master:9000/input/ngram.csv", header=True, schema=schema,sep='\t').limit(100)
df.show(5)
df.printSchema()

# Register the created DataFrame as a temporary table.
df.createOrReplaceTempView("ngram_table")

# Return bigrams with Count > 5
# ----SQL
spark.sql("SELECT * FROM ngram_table WHERE Count > 5").show()

# ----API
df.filter(col("Count") > 5).show()

# Return the total number of bigrams for each year.
# ----SQL
spark.sql("SELECT Year, COUNT(*) AS total FROM ngram_table GROUP BY Year").show()

# ---- API
df.groupBy("Year").count().withColumnRenamed("count", "total").show()

# Return the bigrams with the highest Count for each year.
# --- SQL
spark.sql("""
SELECT Year, ngram, Count
FROM (
    SELECT *, RANK() OVER (PARTITION BY Year ORDER BY Count DESC) AS rank
    FROM ngram_table
)
WHERE rank = 1
""").show()

#--- API
window = Window.partitionBy("Year").orderBy(col("Count").desc())
df.withColumn("rank", rank().over(window)) \
  .filter(col("rank") == 1) \
  .select("Year", "ngram", "Count").show()

# Return all bigrams that appeared in 20 different years.
# --- SQL
spark.sql("SELECT ngram FROM ngram_table GROUP BY ngram HAVING COUNT(DISTINCT Year) = 20").show()

#--- API
df.groupBy("ngram").agg(countDistinct("Year").alias("years")) \
  .filter(col("years") == 20).select("ngram").show()

# Bigrams with ! in first part and 9 in second
# --- SQL
spark.sql("""
SELECT *
FROM ngram_table
WHERE split(ngram, ' ')[0] LIKE '%!%' AND split(ngram, ' ')[1] LIKE '%9%'
""").show()

# --- API
df.filter(
    (split(col("ngram"), " ")[0].contains("!")) &
    (split(col("ngram"), " ")[1].contains("9"))
).show()

# Bigrams appearing in all years
# --- SQL
spark.sql("""
SELECT ngram
FROM ngram_table
GROUP BY ngram
HAVING COUNT(DISTINCT Year) = (SELECT COUNT(DISTINCT Year) FROM ngram_table)
""").show()

# --- API
total_years = df.select(countDistinct("Year")).first()[0]
df.groupBy("ngram").agg(countDistinct("Year").alias("years")) \
  .filter(col("years") == total_years).select("ngram").show()

# Total pages/books per bigram/year
# --- SQL
spark.sql("""
SELECT ngram, Year, SUM(Pages) AS Pages, SUM(Books) AS Books
FROM ngram_table
GROUP BY ngram, Year
ORDER BY ngram
""").show()

# --- API
df.groupBy("ngram", "Year") \
  .agg(sum("Pages").alias("Pages"), sum("Books").alias("Books")) \
  .orderBy("ngram").show()

# Return the total number of distinct bigrams for each year, sorted in descending order of the year.
# --- SQL
spark.sql("""
SELECT Year, COUNT(DISTINCT ngram) AS total
FROM ngram_table
GROUP BY Year
ORDER BY Year DESC
""").show()

# --- API
df.groupBy("Year") \
  .agg(countDistinct("ngram").alias("total")) \
  .orderBy(col("Year").desc()).show()